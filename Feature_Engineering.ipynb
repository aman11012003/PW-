{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **1. What is a parameter?**  \n",
        "A **parameter** is a numerical value that defines a characteristic of a population or a Machine Learning model.  \n",
        "- In statistics, parameters describe the entire population (e.g., population mean, standard deviation).  \n",
        "- In ML, parameters are learned from training data (e.g., weights in neural networks, coefficients in linear regression).  \n",
        "- Parameters help models make accurate predictions.  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. What is correlation?**  \n",
        "**Correlation** measures the relationship between two variables. It ranges from **-1 to +1**:  \n",
        "- **+1** → Perfect positive correlation (both variables increase together).  \n",
        "- **0** → No correlation (no relationship).  \n",
        "- **-1** → Perfect negative correlation (one increases, the other decreases).  \n",
        "\n",
        "---\n",
        "\n",
        "### **3. What does negative correlation mean?**  \n",
        "A **negative correlation** means that as one variable increases, the other decreases.  \n",
        "- Example: As the price of a product increases, the sales decrease.  \n",
        "- It is represented by a **correlation coefficient between -1 and 0**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **4. Define Machine Learning. What are the main components in Machine Learning?**  \n",
        "**Machine Learning (ML)** is a branch of AI that enables computers to learn from data and make predictions.  \n",
        "\n",
        "**Main Components:**  \n",
        "1. **Dataset** – The data used for training/testing.  \n",
        "2. **Features** – Input variables used to make predictions.  \n",
        "3. **Model** – The algorithm that learns patterns from data.  \n",
        "4. **Loss Function** – Measures model error.  \n",
        "5. **Optimizer** – Adjusts parameters to minimize loss.  \n",
        "6. **Evaluation Metrics** – Measures model accuracy (e.g., accuracy, RMSE).  \n",
        "\n",
        "---\n",
        "\n",
        "### **5. How does loss value help in determining whether the model is good or not?**  \n",
        "- The **loss value** quantifies the difference between predicted and actual values.  \n",
        "- **Lower loss** → Better model performance.  \n",
        "- **High loss** → Model needs improvement (e.g., better data, tuning hyperparameters).  \n",
        "- A **good model** has low training and testing loss.  \n",
        "- **Overfitting** occurs if training loss is low but test loss is high.  \n",
        "\n",
        "---\n",
        "\n",
        "### **6. What are continuous and categorical variables?**  \n",
        "- **Continuous Variables** → Numeric variables that can take infinite values (e.g., height, temperature).  \n",
        "- **Categorical Variables** → Variables with fixed categories (e.g., gender, colors).  \n",
        "- ML models require categorical variables to be converted into numerical form.  \n",
        "\n",
        "---\n",
        "\n",
        "### **7. How do we handle categorical variables in Machine Learning? What are the common techniques?**  \n",
        "Categorical variables need to be encoded for ML models.  \n",
        "\n",
        "**Common Techniques:**  \n",
        "1. **One-Hot Encoding** – Converts categories into binary columns (e.g., Male → [1,0], Female → [0,1]).  \n",
        "2. **Label Encoding** – Assigns numerical labels to categories (e.g., Red → 1, Blue → 2).  \n",
        "3. **Ordinal Encoding** – Used for ranked categories (e.g., Small → 1, Medium → 2, Large → 3).  \n",
        "\n",
        "---\n",
        "\n",
        "### **8. What do you mean by training and testing a dataset?**  \n",
        "- **Training Set** → Used to train the ML model.  \n",
        "- **Testing Set** → Used to evaluate the model's performance.  \n",
        "- Splitting data into training and testing prevents **overfitting**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **9. What is sklearn.preprocessing?**  \n",
        "`sklearn.preprocessing` is a **Scikit-Learn** module for data preprocessing.  \n",
        "It provides tools for:  \n",
        "- **Scaling** (StandardScaler, MinMaxScaler)  \n",
        "- **Encoding categorical variables** (OneHotEncoder, LabelEncoder)  \n",
        "- **Handling missing values** (SimpleImputer)  \n",
        "\n",
        "---\n",
        "\n",
        "### **10. What is a Test set?**  \n",
        "The **Test set** is a portion of the dataset **not used for training** but for evaluating the model’s performance.  \n",
        "It helps determine how well the model generalizes to new, unseen data.  \n",
        "\n",
        "---\n",
        "\n",
        "### **11. How do we split data for model fitting (training and testing) in Python?**  \n",
        "Using **train_test_split** from `sklearn.model_selection`:  \n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "Here, **20% of data** is used for testing.  \n",
        "\n",
        "---\n",
        "\n",
        "### **12. How do you approach a Machine Learning problem?**  \n",
        "1. **Understand the problem** – Define the objective.  \n",
        "2. **Collect data** – Gather and preprocess data.  \n",
        "3. **EDA (Exploratory Data Analysis)** – Identify patterns, missing values, and outliers.  \n",
        "4. **Feature Engineering** – Transform variables, handle missing data.  \n",
        "5. **Split data** – Divide into training/testing sets.  \n",
        "6. **Select a model** – Choose an appropriate ML algorithm.  \n",
        "7. **Train the model** – Fit the model using training data.  \n",
        "8. **Evaluate performance** – Use test data to check accuracy.  \n",
        "9. **Optimize and Tune** – Improve the model by tuning hyperparameters.  \n",
        "\n",
        "---\n",
        "\n",
        "### **13. Why do we have to perform EDA before fitting a model to the data?**  \n",
        "EDA helps:  \n",
        "- Identify missing values and outliers.  \n",
        "- Understand feature distributions.  \n",
        "- Find correlations between variables.  \n",
        "- Select the most relevant features.  \n",
        "- Improve model accuracy by preprocessing data properly.  \n",
        "\n",
        "---\n",
        "\n",
        "### **14. How can you find correlation between variables in Python?**  \n",
        "Using `pandas.corr()`:  \n",
        "```python\n",
        "import pandas as pd\n",
        "df.corr()\n",
        "```\n",
        "Using `seaborn` heatmap:  \n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **15. What is causation? Explain difference between correlation and causation with an example.**  \n",
        "- **Correlation** → Two variables move together, but one **does not cause** the other.  \n",
        "- **Causation** → One variable **directly affects** the other.  \n",
        "\n",
        "**Example:**  \n",
        "- **Correlation:** Ice cream sales & shark attacks increase in summer.  \n",
        "- **Causation:** Increased temperature **causes** more ice cream sales.  \n",
        "\n",
        "---\n",
        "\n",
        "### **16. What is an Optimizer? What are different types of optimizers?**  \n",
        "An **optimizer** updates model parameters to minimize loss.  \n",
        "\n",
        "**Types of Optimizers:**  \n",
        "1. **Gradient Descent** – Adjusts weights based on gradients.  \n",
        "2. **SGD (Stochastic Gradient Descent)** – Faster but noisier updates.  \n",
        "3. **Adam (Adaptive Moment Estimation)** – Efficient and widely used.  \n",
        "\n",
        "---\n",
        "\n",
        "### **17. What is sklearn.linear_model?**  \n",
        "`sklearn.linear_model` provides Scikit-Learn’s **linear models**, including:  \n",
        "- **LinearRegression** (for regression tasks).  \n",
        "- **LogisticRegression** (for classification tasks).  \n",
        "- **Ridge and Lasso Regression** (for regularization).  \n",
        "\n",
        "---\n",
        "\n",
        "### **18. What does model.fit() do? What arguments must be given?**  \n",
        "**model.fit()** trains the model using data.  \n",
        "\n",
        "Example:  \n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "Arguments:  \n",
        "- `X_train` → Features.  \n",
        "- `y_train` → Target variable.  \n",
        "\n",
        "---\n",
        "\n",
        "### **19. What does model.predict() do? What arguments must be given?**  \n",
        "**model.predict()** makes predictions on new data.  \n",
        "\n",
        "Example:  \n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "Arguments:  \n",
        "- `X_test` → Feature dataset for prediction.  \n",
        "\n",
        "---\n",
        "\n",
        "### **20. What is Feature Scaling? How does it help in Machine Learning?**  \n",
        "Feature Scaling normalizes data so that all features contribute equally.  \n",
        "It improves performance for **distance-based models** (e.g., KNN, SVM).  \n",
        "\n",
        "---\n",
        "\n",
        "### **21. How do we perform Scaling in Python?**  \n",
        "Using `StandardScaler`:  \n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "Using `MinMaxScaler`:  \n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **22. Explain Data Encoding.**  \n",
        "Data encoding converts categorical data into numerical form.  \n",
        "\n",
        "**Types:**  \n",
        "1. **Label Encoding** – Assigns numbers to categories.  \n",
        "2. **One-Hot Encoding** – Converts categories into binary columns.  \n",
        "3. **Ordinal Encoding** – Used for ordered categories.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8qAx7zuaXdDW"
      }
    }
  ]
}